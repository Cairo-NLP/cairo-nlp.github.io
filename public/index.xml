<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cairo NLP</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Cairo NLP</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>cairo.nlp.group@gmail.com (cAIro|NLP Group)</managingEditor>
    <webMaster>cairo.nlp.group@gmail.com (cAIro|NLP Group)</webMaster>
    <lastBuildDate>Mon, 10 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Arabic NLP Papers Explorer</title>
      <link>http://localhost:1313/paper-digest/arabic-nlp-viz/</link>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate><author>cairo.nlp.group@gmail.com (cAIro|NLP Group)</author>
      <guid>http://localhost:1313/paper-digest/arabic-nlp-viz/</guid>
      <description>Interactive UMAP visualization of research papers in Arabic NLP conferences (2023‚Äì2025) üó∫Ô∏è Go to Interactive Map ‚Üí OR üìñ Continue to Read the Code ‚Üì The ArabicNLP conference series began in 2023 with the first edition, ArabicNLP 2023 @ EMNLP 2023, organized by SIGARAB (the ACL Special Interest Group on Arabic NLP) and co-located with EMNLP 2023 in Singapore (December 7 2023).&#xA;Main conference: 80 submissions ¬∑ 38 accepted (47%) Shared tasks: 5 overview papers ¬∑ 48 system papers The second edition, ArabicNLP 2024, took place on August 16 2024 in Bangkok, Thailand, co-located with ACL 2024.</description>
    </item>
    <item>
      <title>Reasoning with Brain-Like Specialization</title>
      <link>http://localhost:1313/talks/talk_3/badr_talk/</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0000</pubDate><author>cairo.nlp.group@gmail.com (cAIro|NLP Group)</author>
      <guid>http://localhost:1313/talks/talk_3/badr_talk/</guid>
      <description>Abstract Human cognition relies on specialized brain networks for language, logic, and social reasoning. Inspired by this organization, we introduce Mixture of Cognitive Reasoners (MiCRo) ‚Äî a modular transformer that develops brain-like specialization across experts. Each expert aligns with a distinct cognitive domain, enabling interpretable behavior and controllable reasoning. These experts are causally meaningful: ablating one selectively impairs its domain, while routing tokens toward specific experts steers the model‚Äôs outputs. MiCRo matches or surpasses standard baselines on reasoning and human behavioral benchmarks, demonstrating that cognitive modularity can enhance both performance and interpretability.</description>
    </item>
    <item>
      <title>Arabic NLP Tools and Datasets</title>
      <link>http://localhost:1313/talks/talk_2/jarrar_talk/</link>
      <pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate><author>cairo.nlp.group@gmail.com (cAIro|NLP Group)</author>
      <guid>http://localhost:1313/talks/talk_2/jarrar_talk/</guid>
      <description>Abstract Overview of open-source tools and datasets developed for Arabic morphology analysis, Arabic dialects, lexicographic databases, named entity recognition, relation and event extraction, word sense disambiguation, semantic analysis, synonym generation, hate speech detection, LLM instruction and benchmarking datasets, among others&#xA;Speaker Bio Professor of Artificial Intelligence and the director of SinaLab for Computational Linguistics and Artificial Intelligence at both, Hamad Bin Khalifa University/Qatar and Birzeit University/Palestine.&#xA;Recording </description>
    </item>
    <item>
      <title>Getting Started with LLMs and RAG</title>
      <link>http://localhost:1313/talks/talk_1/hassan_talk/</link>
      <pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate><author>cairo.nlp.group@gmail.com (cAIro|NLP Group)</author>
      <guid>http://localhost:1313/talks/talk_1/hassan_talk/</guid>
      <description>Abstract Large Language Models (LLMs) have revolutionized natural language processing, but they face challenges with hallucination and outdated knowledge. This introductory talk explores Retrieval-Augmented Generation (RAG) as a solution that combines the reasoning capabilities of LLMs with real-time information retrieval from external knowledge sources. Perfect for beginners wanting to understand the RAG paradigm and experienced developers looking to implement their first RAG application.&#xA;Speaker Bio Hassan is Senior Applied Scientist at Microsoft, with more than 6 years of experience within NLP and AI across multilple locations along with Egypt, US, UK and Canada.</description>
    </item>
    <item>
      <title>1. Abstraction of NLP - ÿ™ÿ¨ÿ±ŸäÿØŸè ŸÖÿπÿßŸÑÿ¨ÿ©Ÿê ÿßŸÑŸÑÿ∫ÿßÿ™Ÿê ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ©</title>
      <link>http://localhost:1313/eli5/post_1/</link>
      <pubDate>Wed, 11 Sep 2024 00:00:00 +0000</pubDate><author>cairo.nlp.group@gmail.com (cAIro|NLP Group)</author>
      <guid>http://localhost:1313/eli5/post_1/</guid>
      <description>We as humans, by nature, understand text &amp;ldquo;natural language&amp;rdquo;; machines, by nature, understand numbers (in one way or another numerical representation).&#xA;If we want to visualize any NLP task, it could be viewed as:&#xA;Taking text as input. Preprocessing it and getting the numerical representation of this text. Passing it to a model to &amp;ldquo;understand&amp;rdquo; the input to extract the needed features and perform the given task. Taking the output from the model, which would be represented as some numerical representation as well, and post-processing it to convert this output into some text (if needed).</description>
    </item>
  </channel>
</rss>
